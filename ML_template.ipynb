{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adb506d-5318-4d4f-b055-08cd89618f51",
   "metadata": {},
   "source": [
    "# Project Name\n",
    "\n",
    "[Project Description]\n",
    "\n",
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be7ec1-1ba8-475e-a0e6-4bfd8d0f7bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48df9715-96fb-4a55-95b7-99e5be5604c2",
   "metadata": {},
   "source": [
    "# 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01708925-8eac-418a-9232-773c83091304",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058b668-bab1-4a6c-97c1-aa109bc33ba0",
   "metadata": {},
   "source": [
    "# 2. Understand the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a19e4cc-3417-490e-bf00-c0935b46fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head(5))\n",
    "display(test_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501a7fa-fbde-4752-9360-7abd9841c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.info())\n",
    "display(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece6a3d-e20e-47c1-985a-5c2d9c8e9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab2833e-a7da-41e1-8363-13f7b7ef8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6767075-df92-46f7-942e-936e9ea65378",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning\n",
    "\n",
    "## 3.1. Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b665d-76ee-48a7-945e-2f10a176418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a22dc2-2b47-4d78-acc1-a63ad56e4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5cab2b-b8d9-4694-b419-52a8fcd1139f",
   "metadata": {},
   "source": [
    "## 3.2. Check for missing data\n",
    "Let's check for 0, blank, NaN or None values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b16b2f-009c-4576-8185-59a2356698e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_values(df):\n",
    "    \"\"\" \n",
    "    calculate the 0, blank, NaN or None values in df, in count and %\n",
    "    filter rows where not all values are 0\n",
    "    \"\"\"\n",
    "\n",
    "    missing_df = pd.concat([\n",
    "        # Counts\n",
    "        (df == 0).sum().rename('zeros_count'),\n",
    "        (df == '').sum().rename('blanks_count'), \n",
    "        df.isna().sum().rename('nan_count'),\n",
    "        (df == None).sum().rename('none_count'),\n",
    "        \n",
    "        # Percentages\n",
    "        ((df == 0).sum() / len(df) * 100).round(1).rename('zeros_%'),\n",
    "        ((df == '').sum() / len(df) * 100).round(1).rename('blanks_%'), \n",
    "        (df.isna().sum() / len(df) * 100).round(1).rename('nan_%'),\n",
    "        ((df == None).sum() / len(df) * 100).round(1).rename('none_%')\n",
    "    ], axis=1)\n",
    "\n",
    "    # Filter rows where not all values are zero\n",
    "    missing_df = missing_df[(missing_df.select_dtypes(include=[np.number]) != 0).any(axis=1)]\n",
    "\n",
    "    # Sort by zeros count (descending) and then by NaN count (descending)\n",
    "    missing_df = missing_df.sort_values(['zeros_count', 'nan_count'], ascending=[False, False])\n",
    "\n",
    "    display(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b4295-f8da-49e0-b43a-0aaae3c9290d",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis\n",
    "\n",
    "## 4.1. Univariate analysis\n",
    "\n",
    "For each categorical variable, display the bar plot.\n",
    "\n",
    "For each numerical variable, show histograms, measures of central tendency (mean, median, mode), and measures of dispersion (range, standard deviation, skewness, kurtosis). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c53ea1-9cb3-4e6a-923d-26aa7a658b59",
   "metadata": {},
   "source": [
    "## 4.2. Bivariate analysis\n",
    "\n",
    "Understand the relationships between features and the target variable using scatterplots, correlation coefficients / matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c5f085-c07b-4629-88a6-63c70f9dd7ad",
   "metadata": {},
   "source": [
    "## 4.3. Handle Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18df6af-165c-4a71-ac9a-399b343c4f90",
   "metadata": {},
   "source": [
    "## 4.4. Handle missing values\n",
    "\n",
    "**IMPORTANT!** Don't impute missing values using the test set! This is a common mistake leading to **Data Leakage** by train-test contamination. Use SimpleImputer to prevent data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84204f8b-d89d-4654-939b-43b9b4a03981",
   "metadata": {},
   "source": [
    "# 5. Feature engineering\n",
    "\n",
    "## 5.1. Create new features\n",
    "\n",
    "Let's engineer relevant features that might improve predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90aa67c-4ec5-4c2f-86db-375aac3e173d",
   "metadata": {},
   "source": [
    "## 5.2. Encode categorical features\n",
    "\n",
    "Let's convert categorical features into numerical form using techniques like one-hot encoding, label encoding or target encoding.\n",
    "\n",
    "Note : using drop_first=True creates 1 column instead of 2 for 2 categories (dummy variable trapping). This avoids multicollinearity between columns.\n",
    "\n",
    "Target encoding preserves the relationship between categorical values and the target variable, which can improve model performance compared to simple label encoding or one-hot encoding for tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b332188-18fe-44dd-87ef-c9ad9258850e",
   "metadata": {},
   "source": [
    "## 5.3. Feature selection\n",
    "\n",
    "Let's remove features that do not contribute much to the prediction, such as colinear features or features poorly correlated with the target variable.\n",
    "\n",
    "Many ML algorithms, such as Random Forest, provide a feature importance score.\n",
    "\n",
    "This improves the model's stability and interpretability, and reduces overfitting. \n",
    "\n",
    "The Spearman correlation coefficient is able to pick up relationships between variables even when they are nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2695afc-bf4a-409c-8b69-de964d6d0066",
   "metadata": {},
   "source": [
    "## 5.4. Feature Normalization\n",
    "\n",
    "Many regression models assume normally distributed data. Let's fix skewed features by applying log transform to the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a409d-ebdc-4cf7-96ec-ac5e18878f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in quantitative:\n",
    "    train[col] = np.log1p(train[col])\n",
    "    test[col] = np.log1p(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a066e2-26b5-4a43-8ccd-1d97943b6a43",
   "metadata": {},
   "source": [
    "## 5.5. Feature Scaling\n",
    "\n",
    "Scaling numerical features improves distance-based calculations (for KNN, SVM classifiers) and prevents feature dominance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60cd243-7727-48b6-9e76-a6199abdfb8d",
   "metadata": {},
   "source": [
    "## 5.6. Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd74cad-1a09-49d1-a05f-00b572bf4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train_clean.csv', index=False)\n",
    "test.to_csv('data/test_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797aa12-2834-4740-ab96-f22c8393bc26",
   "metadata": {},
   "source": [
    "# 6. Choose an Evaluation Metrics\n",
    "For regression problems, common metrics include:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- R-squared\n",
    "\n",
    "For classification problems, common metrics include:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- AUC\n",
    "\n",
    "The confusion matric and ROC Curve can also bring useful insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a741ef0-de39-4092-9f07-67cb983fd46c",
   "metadata": {},
   "source": [
    "# 7. Select Algorithms\n",
    "- Start with simple regression algorithms like Linear Regression and gradually explore more complex models like Random Forest, Gradient Boosting, or XGBoost.\n",
    "- Consider simple ensemble methods, such as simple average, weighted average, or voting ensembles, to combine multiple models for potentially better results.\n",
    "- The model chosen depends on the data. A more complex model does not always constitute a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebe25d-1537-4a4d-9b0b-f5bf8633fdc7",
   "metadata": {},
   "source": [
    "# 8. Model Validation\n",
    "- Split the data into training and validation sets. A common split is 70-30 or 80-20 for training and validation, respectively. This method is computationally less intensive and often used for initial model exploration or when dealing with very large datasets.\n",
    "- K-Fold Cross Validation. This method provides a more reliable evaluation, especially with smaller datasets.\n",
    "- Model validation is important to assess the model's generalization performance (i.e. assess how well the model performs on unseen data). This helps prevent overfitting and gives you a more reliable estimate of your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff442d8d-b181-468c-9b8c-2cc33188ecb1",
   "metadata": {},
   "source": [
    "## 8.1. Hyperparameter Tuning\n",
    "- Tune the hyperparameters of your chosen algorithms on the validation dataset using techniques like grid search or random search to find the best combination.\n",
    "- Optuna is an efficient and effective way to search for optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e9540-8600-4059-9f5e-bb816adf1009",
   "metadata": {},
   "source": [
    "## 8.2. Regularization\n",
    "- Implement regularization techniques like L1 (Lasso) or L2 (Ridge) regularization to prevent overfitting.\n",
    "- Many ML algorithms include regularization parameters, including L1 and L2, sometimes called reg_alpha or reg_lambda. Read up on your chosen algorithms regularization parameters and tune them accordingly on your validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7e197-0897-4ffb-8429-c481462e7f48",
   "metadata": {},
   "source": [
    "# 9. Fit the final model\n",
    "\n",
    "Fit the best model on the whole training set (including the validation set) using the optimal hyperparameters found during model validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687ca94-d9c8-43eb-a567-5c526a3d9556",
   "metadata": {},
   "source": [
    "# 10. Predict\n",
    "\n",
    "Generate predictions on the test set (unseen data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d22384-2b9d-40b7-b7a2-00c305a23091",
   "metadata": {},
   "source": [
    "# 11. Model Persistence\n",
    "Save the model weights for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e02ea-ea18-44de-b3a3-52eefad28575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d7e5e-a597-4b83-8250-099859ca1d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
