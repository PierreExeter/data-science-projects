{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adb506d-5318-4d4f-b055-08cd89618f51",
   "metadata": {},
   "source": [
    "# House Price Prediction\n",
    "\n",
    "The goal of this project is to predict the sales price of residential homes in Ames, Iowa, USA based on various of attributes. It is a supervised regression problem.\n",
    "\n",
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3be7ec1-1ba8-475e-a0e6-4bfd8d0f7bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV, LassoCV, RidgeCV, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "import joblib\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df9715-96fb-4a55-95b7-99e5be5604c2",
   "metadata": {},
   "source": [
    "# 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01708925-8eac-418a-9232-773c83091304",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_cleaned_2.csv\", header=0)\n",
    "test = pd.read_csv(\"data/test_cleaned_2.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797aa12-2834-4740-ab96-f22c8393bc26",
   "metadata": {},
   "source": [
    "# 6. Choose an Evaluation Metrics\n",
    "For regression problems, common metrics include:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- R-squared\n",
    "\n",
    "For classification problems, common metrics include:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- AUC\n",
    "\n",
    "The confusion matric and ROC Curve can also bring useful insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f814a0f9-d5b8-445a-8b99-80d99f19ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return root_mean_squared_error(y, y_pred)\n",
    "\n",
    "def cv_rmse(model, X, y):\n",
    "    return np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50089933-f10f-4fb7-8283-7e50d2a519d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning model\n",
    "\n",
    "X_train = train.drop(columns=['SalePrice', 'Id'])\n",
    "X_test = test.drop(columns=['Id'])\n",
    "y_train = train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a741ef0-de39-4092-9f07-67cb983fd46c",
   "metadata": {},
   "source": [
    "# 7. Select Algorithms\n",
    "- Start with simple regression algorithms like Linear Regression and gradually explore more complex models like Random Forest, Gradient Boosting, or XGBoost.\n",
    "- Consider simple ensemble methods, such as simple average, weighted average, or voting ensembles, to combine multiple models for potentially better results.\n",
    "- The model chosen depends on the data. A more complex model does not always constitute a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee226cd-66c6-45e8-a647-49f1ba3c3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710501bb-3240-482b-af1a-f506095320d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'SGD Regressor': SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'K-Neighbors': KNeighborsRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13c1669-3f72-4dbf-b1f8-e1164231ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e577940a-6ce6-4b18-b000-5bf1a7758b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \n",
    "sdrg = SGDRegressor()\n",
    "dtr = DecisionTreeRegressor()\n",
    "rfr = RandomForestRegressor()\n",
    "knr = KNeighborsRegressor()\n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n",
    "gbr = GradientBoostingRegressor(\n",
    "    n_estimators=3000, \n",
    "    learning_rate=0.05, \n",
    "    max_depth=4, \n",
    "    max_features='sqrt', \n",
    "    min_samples_leaf=15, \n",
    "    min_samples_split=10, \n",
    "    loss='huber', \n",
    "    random_state=42)\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                         num_leaves=4,\n",
    "                         learning_rate=0.01,\n",
    "                         n_estimators=5000,\n",
    "                         max_bin=200,\n",
    "                         bagging_fraction=0.75,\n",
    "                         bagging_freq=5,\n",
    "                         bagging_seed=7,\n",
    "                         feature_fraction=0.2,\n",
    "                         feature_fraction_seed=7,\n",
    "                         verbose=-1)\n",
    "xgboost = XGBRegressor(learning_rate=0.01,\n",
    "                       n_estimators=3460,\n",
    "                       max_depth=3, \n",
    "                       min_child_weight=0,\n",
    "                       gamma=0, \n",
    "                       subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:linear', \n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight=1, \n",
    "                       seed=27,\n",
    "                       reg_alpha=0.00006)\n",
    "stack_gen = StackingCVRegressor(\n",
    "    regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "    meta_regressor=xgboost,\n",
    "    use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebe25d-1537-4a4d-9b0b-f5bf8633fdc7",
   "metadata": {},
   "source": [
    "# 8. Model Validation\n",
    "- Split the data into training and validation sets. A common split is 70-30 or 80-20 for training and validation, respectively. This method is computationally less intensive and often used for initial model exploration or when dealing with very large datasets.\n",
    "- K-Fold Cross Validation. This method provides a more reliable evaluation, especially with smaller datasets.\n",
    "- Model validation is important to assess the model's generalization performance (i.e. assess how well the model performs on unseen data). This helps prevent overfitting and gives you a more reliable estimate of your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b71671-7593-491f-881a-05e4016e2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(model, X_train, X_test, y_train, cv_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Train a regression model and assess performance using RMSE\n",
    "    model: eg. model = LinearRegression()\n",
    "    X_train: train dataframe without the target column\n",
    "    X_test: test dataframe    \n",
    "    y_train: target column\n",
    "    cv_folds: number of cross-validation folds\n",
    "    random_state: random state for reproducibility\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use model class name as model name\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"Training: {model_name}\")    \n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Perform cross-validation with RMSE scoring\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    rmse_scores = np.sqrt(-cross_val_score(model, X_train, y_train, \n",
    "                                         scoring='neg_mean_squared_error', \n",
    "                                         cv=kf, n_jobs=-1))\n",
    "    \n",
    "    cv_rmse_mean = np.mean(rmse_scores)\n",
    "    \n",
    "    # Predictions on train set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # Predict on test set \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics on training data\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    \n",
    "    # Create results dictionary\n",
    "    results_dict = {\n",
    "        'Model_Name': model_name,\n",
    "        'Train_RMSE': train_rmse,\n",
    "        'CV_RMSE_Mean': cv_rmse_mean\n",
    "    }\n",
    "    \n",
    "    return y_pred_test, y_pred_train, results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c42d258-e477-40f2-b7fb-d38c95f374a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: LinearRegression\n"
     ]
    }
   ],
   "source": [
    "# fit all regression models\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    y_pred_test, y_pred_train, results = regression_model(\n",
    "        model, X_train, X_test, y_train, cv_folds=5\n",
    "    )\n",
    "    all_results[model_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f6fa55-57a9-4178-b97c-53b2e0f370f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>CV_RMSE_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model_Name  Train_RMSE  CV_RMSE_Mean\n",
       "Linear Regression  LinearRegression        0.12          0.13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print result dataframe\n",
    "results_df = pd.DataFrame.from_dict(all_results, orient='index')\n",
    "results_df = results_df.sort_values('CV_RMSE_Mean').round(4)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31cb76d-9e73-4896-8d98-52ef8210bb7e",
   "metadata": {},
   "source": [
    "## 8.1. Hyperparameter Tuning\n",
    "- Tune the hyperparameters of your chosen algorithms on the validation dataset using techniques like grid search or random search to find the best combination.\n",
    "- Optuna is an efficient and effective way to search for optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69922622-d19e-4d06-8c01-2dc3b3d10c52",
   "metadata": {},
   "source": [
    "## 8.2. Regularization\n",
    "- Implement regularization techniques like L1 (Lasso) or L2 (Ridge) regularization to prevent overfitting.\n",
    "- Many ML algorithms include regularization parameters, including L1 and L2, sometimes called reg_alpha or reg_lambda. Read up on your chosen algorithms regularization parameters and tune them accordingly on your validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7e197-0897-4ffb-8429-c481462e7f48",
   "metadata": {},
   "source": [
    "# 9. Train the final model\n",
    "\n",
    "Fit the best model using the optimal hyperparameters found on the whole training set (including the validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc9d9b35-481b-4f99-91f8-5d11cbf27317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: GradientBoostingRegressor\n"
     ]
    }
   ],
   "source": [
    "best_model = GradientBoostingRegressor(random_state=42)\n",
    "y_pred_test, y_pred_train, _ = regression_model(best_model, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687ca94-d9c8-43eb-a567-5c526a3d9556",
   "metadata": {},
   "source": [
    "# 10. Predictions\n",
    "\n",
    "Generate predictions on the test set (unseen data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdaecc9d-7481-4566-b97a-25ef0cb8d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert the log transform to get the original SalePrice values\n",
    "test['SalePrice'] = np.expm1(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75408152-4829-4a14-9b1c-018bb19cc721",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': test['Id'],\n",
    "    'SalePrice': test['SalePrice']\n",
    "})\n",
    "\n",
    "submission.to_csv('predictions/gbr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de916ad8-468f-49e0-9983-31dcfa7c6183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>124828.882404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>160974.370860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>184168.642459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>184974.732709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>203586.188866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1466</td>\n",
       "      <td>176096.563794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1467</td>\n",
       "      <td>171886.047427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1468</td>\n",
       "      <td>162649.686668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1469</td>\n",
       "      <td>190877.728835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1470</td>\n",
       "      <td>119355.577115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  124828.882404\n",
       "1  1462  160974.370860\n",
       "2  1463  184168.642459\n",
       "3  1464  184974.732709\n",
       "4  1465  203586.188866\n",
       "5  1466  176096.563794\n",
       "6  1467  171886.047427\n",
       "7  1468  162649.686668\n",
       "8  1469  190877.728835\n",
       "9  1470  119355.577115"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3cf95-4f6d-44d9-b714-c7d79bd53ba9",
   "metadata": {},
   "source": [
    "# 11. Model Persistence\n",
    "\n",
    "Save the model weights for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a5e02ea-ea18-44de-b3a3-52eefad28575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(best_model, 'models/gbr.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('models/gbr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fdb550-d3c4-4388-95fa-22de00027d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
